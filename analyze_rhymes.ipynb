{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to detect three types of rhyming techniques: \n",
    "- assonance.\n",
    "- mutli-syllable rhymes.\n",
    "- rhyming schemes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read data: \n",
    "Read the lyrics in a list of lines. \n",
    "- preprocessing steps: \n",
    "1. remove special characters. \n",
    "2. remove maningless words? (implement it but keep it open). \n",
    "3. create a vowel representation for each word (assonance detection)\n",
    "4. create a syllable representation of each word (multis detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'come']\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "\n",
    "# Create an instance of the Pyphen class using the 'en' dictionary for English language\n",
    "dic = pyphen.Pyphen(lang='en_US')\n",
    "\n",
    "# Get the syllables of a word\n",
    "word = 'income'\n",
    "syllables = dic.inserted(word).split('-')\n",
    "\n",
    "print(syllables)  # Output: ['ex', 'am', 'ple']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zohabidi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "new_stop_words = ['ooh','yeah','hey','whoa','woah', 'ohh', 'was', 'mmm', 'oooh','yah','yeh','mmm', 'hmm','deh','doh','jah','wa']\n",
    "stop_words.extend(new_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "lines,words = [], []\n",
    "punctuation = string.punctuation.replace(\"'\", \"\")\n",
    "translation_table = str.maketrans(punctuation, ' ' * len(punctuation))\n",
    "\n",
    "def remove_extra_spaces(input_string):\n",
    "    # Split the string into words and join them with a single space\n",
    "    return ' '.join(input_string.split())\n",
    "\n",
    "with open(\"BarBreakDown\\\\lyrics_en\\\\2pac\\\\Hit_'Em_Up.txt\", 'r') as file:\n",
    "    # Iterate over each line in the file\n",
    "    for line in file:\n",
    "        # Strip leading/trailing whitespace from the line\n",
    "        line = line.replace(\"\\n\", \" \")\n",
    "        # Replace punctuation marks with spaces\n",
    "        line = line.translate(translation_table)\n",
    "        line = remove_extra_spaces(line)\n",
    "        ## remove stopwords not so sure about it. \n",
    "        \n",
    "        lines.append(line)\n",
    "        words.append(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"ain't\", 'got', 'no', \"motherfuckin'\", 'friends', 'sucka', 'ass']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M0RFKN'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create vowel representation: \n",
    "import phonetics\n",
    "#ph.get_phonetic_transcription('bath')\n",
    "phonetics.metaphone('motherfuckin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rhyming words\n",
    "phonetics.metaphone('friends')[-1] == phonetics.metaphone('ass')[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar1 = \"sling some raps\"\n",
    "bar2 = \"income tax\"\n",
    "\n",
    "words_bar1 = bar1.split(\" \")\n",
    "words_bar2 = bar2.split(\" \")\n",
    "\n",
    "bar1_syllables,bar2_syllables = [],[]\n",
    "bar1_ph_syllables,bar2_ph_syllables = [],[]\n",
    "\n",
    "\n",
    "for word in words_bar1:\n",
    "    syllables = dic.inserted(word).split('-')\n",
    "    bar1_syllables.append(syllables)\n",
    "    syllables_ph = []\n",
    "    for syllable in syllables:\n",
    "        syllables_ph.append(phonetics.nysiis(syllable))\n",
    "    bar1_ph_syllables.append(syllables_ph)\n",
    "\n",
    "for word in words_bar2:\n",
    "    syllables = dic.inserted(word).split('-')\n",
    "    bar2_syllables.append(syllables)\n",
    "    syllables_ph = []\n",
    "    for syllable in syllables:\n",
    "        syllables_ph.append(phonetics.nysiis(syllable))\n",
    "    bar2_ph_syllables.append(syllables_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SA'], ['SANA'], ['RA']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar1_ph_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['IA', 'CANA'], ['TA']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar2_ph_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar1 = \"Cold Winter Day so I wear my jacket\" \n",
    "bar2 = \"gold winners play because life is a game\"\n",
    "\n",
    "words_bar1 = bar1.split(\" \")\n",
    "words_bar2 = bar2.split(\" \")\n",
    "\n",
    "bar1_syllables,bar2_syllables = [],[]\n",
    "bar1_ph_syllables,bar2_ph_syllables = [],[]\n",
    "\n",
    "\n",
    "for word in words_bar1:\n",
    "    syllables = dic.inserted(word).split('-')\n",
    "    bar1_syllables.append(syllables)\n",
    "    syllables_ph = []\n",
    "    for syllable in syllables:\n",
    "        syllables_ph.append(phonetics.metaphone(syllable))\n",
    "    bar1_ph_syllables.append(syllables_ph)\n",
    "\n",
    "for word in words_bar2:\n",
    "    syllables = dic.inserted(word).split('-')\n",
    "    bar2_syllables.append(syllables)\n",
    "    syllables_ph = []\n",
    "    for syllable in syllables:\n",
    "        syllables_ph.append(phonetics.metaphone(syllable))\n",
    "    bar2_ph_syllables.append(syllables_ph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KLT'], ['AN', 'TR'], ['T'], ['S'], ['A'], ['AR'], ['M'], ['JK', 'AT']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar1_ph_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KLT'], ['AN', 'NRS'], ['PL'], ['P', 'KS'], ['LF'], ['AS'], ['A'], ['KM']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar2_ph_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein similarity: 0.57\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def levenshtein_similarity(str1, str2):\n",
    "    # Calculate the Levenshtein distance\n",
    "    distance = Levenshtein.distance(str1, str2)\n",
    "    # Calculate the similarity ratio\n",
    "    similarity = 1 - (distance / max(len(str1), len(str2)))\n",
    "    return similarity\n",
    "\n",
    "# Example usage\n",
    "str1 = \"KLT AN TR T S A AR\"\n",
    "str2 = \"KLT AN NRS PL P KS LF\"\n",
    "similarity = levenshtein_similarity(str1, str2)\n",
    "print(f\"Levenshtein similarity: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def difflib_similarity(str1, str2):\n",
    "    # Create a SequenceMatcher object\n",
    "    matcher = SequenceMatcher(None, str1, str2)\n",
    "    # Calculate the similarity ratio\n",
    "    similarity = matcher.ratio()\n",
    "    return similarity\n",
    "\n",
    "#similarity = difflib_similarity(str1, str2)\n",
    "#print(f\"difflib similarity: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract multi syllable rhymes --> assonance extraction --> rhyme schemes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['B', 'C'], ['B', 'C'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_threshold = 0.75\n",
    "def detect_multi_rhymes(current_line_syllables, next_line_syllables):\n",
    "    ## for each syllable in the current line check current line and next line. \n",
    "    # if you find matching syllables, start concatenating the matching syllable strings, stop when the similarity is under a specific threshold\n",
    "    ## Sample input\n",
    "    ## current_line_syllables = [\"A\", \"B\", \"C\"]\n",
    "    ## next_line_syllables = [\"D\", \"B\", \"C\"]\n",
    "    i=0\n",
    "    mutli_rhymes = []\n",
    "\n",
    "    while(i<(len(current_line_syllables)-1)):\n",
    "\n",
    "        j,extension = 0, 0\n",
    "        lookup_field = current_line_syllables[i+1:] + next_line_syllables\n",
    "\n",
    "        while((i+extension)<len(current_line_syllables) and (j+extension) < len(lookup_field)): \n",
    "            str1 = ' '.join(current_line_syllables[i:i+1+extension])\n",
    "            str2 = ' '.join(lookup_field[j:j+1+extension])\n",
    "\n",
    "            similarity = difflib_similarity(str1, str2)\n",
    "            if similarity >= similarity_threshold:\n",
    "                extension +=1\n",
    "            elif similarity<similarity_threshold and extension >1:\n",
    "                break\n",
    "            elif similarity<similarity_threshold and extension <=1:\n",
    "                j+=1\n",
    "                extension = 0\n",
    "        \n",
    "        if extension >1:\n",
    "            mutli_rhyme = (current_line_syllables[i:i+extension],lookup_field[j:j+extension])   \n",
    "            mutli_rhymes.append(mutli_rhyme)\n",
    "        \n",
    "        i = i+extension+1\n",
    "    \n",
    "    return mutli_rhymes\n",
    "\n",
    "detect_multi_rhymes([\"A\", \"B\", \"C\"], [\"D\", \"B\", \"C\"])\n",
    "#detect_multi_rhymes([\"A\", \"B\", \"C\",\"D\", \"M\", \"N\", \"O\"], [\"E\",\"F\", \"B\", \"L\",\"B\", \"C\", \"D\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KM'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonetics.metaphone(\"com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sling', 'some', 'raps'], ['SLNK', 'SM', 'RPS'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_phonetic_syllable_represtation(line):\n",
    "    words_list = line.split(\" \")\n",
    "    line_syllables,line_syllables_ph = [],[]\n",
    "\n",
    "    for word in words_list:\n",
    "        syllables = dic.inserted(word).split('-')\n",
    "        line_syllables.extend(syllables)\n",
    "        for syllable in syllables:\n",
    "            line_syllables_ph.append(phonetics.metaphone(syllable))\n",
    "    return line_syllables,line_syllables_ph\n",
    "\n",
    "create_phonetic_syllable_represtation(\"sling some raps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each line -> create syllable phonetic representation of current & next line --> call the multi function\n",
    "# -> in case you find something add it to a dict: key:line number -> value: multi tuple. \n",
    "multi_rhymes = {}\n",
    "for line_index in range(len(lines)-1):\n",
    "    _,current_line_syllables_ph=create_phonetic_syllable_represtation(lines[line_index])\n",
    "    _,next_line_syllables_ph=create_phonetic_syllable_represtation(lines[line_index+1])\n",
    "    \n",
    "    multi_rhyme = detect_multi_rhymes(current_line_syllables_ph, next_line_syllables_ph)\n",
    "    if multi_rhyme is not None:\n",
    "        multi_rhymes[line_index] = multi_rhyme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 2.0\n"
     ]
    }
   ],
   "source": [
    "number_multi_rhymes, average_len_multi_rhymes = 0,0\n",
    "for index, (key,value) in enumerate(multi_rhymes.items()):\n",
    "    if len(value)>0:\n",
    "        number_multi_rhymes += 1\n",
    "        average_len_multi_rhymes += len(value[0])\n",
    "\n",
    "print(number_multi_rhymes, average_len_multi_rhymes/number_multi_rhymes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assonance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same logic, you check current line and next line \n",
    "# you need a vowel representation \n",
    "def cut_at_last_vowel(line):\n",
    "    vowels = \"aeiou\"\n",
    "    words = line.split(\" \")\n",
    "    line_vowel_repr = []\n",
    "\n",
    "    for word in words:\n",
    "        last_vowel_pos = -1\n",
    "\n",
    "        # Find the position of the last vowel\n",
    "        for i, char in enumerate(reversed(word.lower())):\n",
    "            if char in vowels:\n",
    "                last_vowel_pos = len(word) - 1 - i\n",
    "                break\n",
    "    \n",
    "        # If no vowel is found, return the original string\n",
    "        if last_vowel_pos != -1:\n",
    "            line_vowel_repr.append(word[:last_vowel_pos + 1].lower()) \n",
    "\n",
    "    return line_vowel_repr\n",
    "\n",
    "def delete_indices_from_list(input_list, indices_to_delete):\n",
    "    # Sort the indices in reverse order\n",
    "    indices_to_delete = sorted(indices_to_delete, reverse=True)\n",
    "    \n",
    "    # Delete elements at the specified indices\n",
    "    for index in indices_to_delete:\n",
    "        del input_list[index]\n",
    "    \n",
    "    return input_list\n",
    "\n",
    "def detect_assonance(current_line_vowel_repr, next_line_vowel_repr):\n",
    "    assonances = []\n",
    "    i = 0\n",
    "    while(i<len(current_line_vowel_repr)):\n",
    "        j = i+1\n",
    "        assonance = []\n",
    "        indices_to_delete_current_line = []\n",
    "        while (j<len(current_line_vowel_repr)):\n",
    "            if current_line_vowel_repr[i][-1] == current_line_vowel_repr[j][-1]: \n",
    "                assonance.append(current_line_vowel_repr[j])\n",
    "                indices_to_delete_current_line.append(j)\n",
    "            j+=1\n",
    "\n",
    "        j = 0\n",
    "        while (j<len(next_line_vowel_repr)):\n",
    "            if current_line_vowel_repr[i][-1] == next_line_vowel_repr[j][-1]: \n",
    "                assonance.append(next_line_vowel_repr[j])\n",
    "            j+=1\n",
    "\n",
    "        if len(assonance):\n",
    "            assonance.insert(0,current_line_vowel_repr[i])\n",
    "            assonances.append(list(set(assonance)))\n",
    "            indices_to_delete_current_line.append(i)\n",
    "            delete_indices_from_list(current_line_vowel_repr, indices_to_delete_current_line)\n",
    "        else:\n",
    "            i+=1\n",
    "    \n",
    "    return assonances\n",
    "\n",
    "#detect_assonance([ \"BA\", \"MAI\", \"LOO\", \"FA\"], [\"TAA\", \"LBO\", \"KKO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assonances = {}\n",
    "for line_index in range(len(lines)-1):\n",
    "    current_line_vowel_repr = cut_at_last_vowel(lines[line_index])\n",
    "    if not len(current_line_vowel_repr):\n",
    "        continue\n",
    "    next_line_vowel_repr = cut_at_last_vowel(lines[line_index+1])\n",
    "    \n",
    "    assonance = detect_assonance(current_line_vowel_repr, next_line_vowel_repr)\n",
    "    if len(assonance):\n",
    "        assonances[line_index] = assonance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assonances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhyme Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_line_schemes = [\"ABAB\",\"XAXA\", \"AAAA\", \"AABB\", \"AXAA\", \"AAXA\", \"ABBA\", \"AXXA\", \"AAAX\"]\n",
    "six_line_schems = [\"XXAXXA\", \"AABCCB\", \"XAAXBB\", \"AABAAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "twopac_lines = lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\"That girl is a real crowd pleaser\",\n",
    "         \"Small world, all her friends know me\",\n",
    "         \"Young bull livin' like an old geezer\",\n",
    "         \"Release the cash, watch it fall slowly\"]\n",
    "# comparison not between actualy characters but pronunciation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m rhyme_schemes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lines)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m---> 30\u001b[0m     remaining_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines)\u001b[38;5;241m-\u001b[39mline_index\n\u001b[0;32m     31\u001b[0m     four_line_endings \u001b[38;5;241m=\u001b[39m lines[line_index][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m lines[line_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m lines[line_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m lines[line_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining_lines \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5\u001b[39m:\n",
      "Cell \u001b[1;32mIn[28], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m rhyme_schemes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lines)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m---> 30\u001b[0m     remaining_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines)\u001b[38;5;241m-\u001b[39mline_index\n\u001b[0;32m     31\u001b[0m     four_line_endings \u001b[38;5;241m=\u001b[39m lines[line_index][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m lines[line_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m lines[line_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m lines[line_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining_lines \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1698\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:636\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1113\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1091\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:496\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zohabidi\\Desktop\\Hackathon\\beef_analysis\\myenv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zohabidi\\Desktop\\Hackathon\\beef_analysis\\myenv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def add_to_rhyme_schemes(dictionary, key_, value_):\n",
    "    if key_ not in rhyme_schemes:\n",
    "        dictionary[key_] = [value_]\n",
    "    else:\n",
    "        dictionary[key_].append(value_)\n",
    "    return dictionary\n",
    "\n",
    "def are_lists_equal(list1, list2):\n",
    "    set1 = set(map(tuple, list1))\n",
    "    set2 = set(map(tuple, list2))\n",
    "    return set1 == set2\n",
    "\n",
    "def analyze_line_endings(line_endings):\n",
    "    # Dictionary to store character information\n",
    "    char_info = {}\n",
    "\n",
    "    # Iterate over the string to collect information\n",
    "    for index, char in enumerate(line_endings):\n",
    "        if char not in char_info:\n",
    "            char_info[char] = {'count': 0, 'indices': []}\n",
    "        char_info[char]['count'] += 1\n",
    "        char_info[char]['indices'].append(index)\n",
    "\n",
    "    return char_info\n",
    "\n",
    "rhyme_schemes = {}\n",
    "\n",
    "for line_index in range(len(lines)-4):\n",
    "\n",
    "    remaining_lines = len(lines)-line_index\n",
    "    four_line_endings = lines[line_index][-1] + lines[line_index+1][-1] + lines[line_index+2][-1] + lines[line_index+3][-1]\n",
    "\n",
    "    if remaining_lines >5:\n",
    "        six_line_endings = four_line_endings + lines[line_index+4][-1] + lines[line_index+5][-1]\n",
    "        six_line_info = analyze_line_endings(six_line_endings)\n",
    "\n",
    "        list_indices=[] \n",
    "        for i,k,v in enumerate(six_line_info):\n",
    "            list_indices.append(v[\"indices\"])\n",
    "\n",
    "        unique_chars = len(six_line_info)\n",
    "        match unique_chars:\n",
    "            case 1:\n",
    "                pass\n",
    "            case 2:\n",
    "                #check if it's AABAAB otherwise pass.\n",
    "                scheme_AABAAB = are_lists_equal(list_indices, [[0,1,3,4], [2,5]])\n",
    "                continue\n",
    "            case 3:\n",
    "                #check if it's AABCCB otherwise pass.\n",
    "                scheme_AABCCB = are_lists_equal(list_indices, [[0,1], [2,5], [3,4]])\n",
    "                continue\n",
    "            case 4:\n",
    "                pass\n",
    "            case 5:\n",
    "                #check if it's XXAXXA otherwise pass.\n",
    "                scheme_XXAXXA = are_lists_equal(list_indices, [[0],[1],[2,5], [3],[4]]) \n",
    "                continue\n",
    "            case 6:\n",
    "                continue #no rhyme scheme found.\n",
    "    \n",
    "    \n",
    "    four_line_info = analyze_line_endings(four_line_endings)\n",
    "\n",
    "    list_indices=[] \n",
    "    for i,k,v in enumerate(four_line_info):\n",
    "        list_indices.append(v[\"indices\"])\n",
    "\n",
    "    unique_chars = len(four_line_info)\n",
    "\n",
    "    match unique_chars:\n",
    "        case 1:\n",
    "            rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"AAAA\", lines[line_index:line_index+4])\n",
    "            continue\n",
    "        case 2:\n",
    "            # can be ABAB, AABB, ABBA,AAXA\n",
    "            scheme_ABAB = are_lists_equal(list_indices, [[0,2],[1,3]])\n",
    "            if scheme_ABAB:\n",
    "                rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"ABAB\", lines[line_index:line_index+4])\n",
    "                continue\n",
    "            \n",
    "            scheme_AABB = are_lists_equal(list_indices, [[0,1], [2,3]])\n",
    "            if scheme_AABB:\n",
    "                rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"AABB\", lines[line_index:line_index+4])\n",
    "                continue\n",
    "\n",
    "            scheme_ABBA = are_lists_equal(list_indices, [[0,3], [1,2]])\n",
    "            if scheme_ABBA:\n",
    "                rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"ABBA\", lines[line_index:line_index+4])\n",
    "                continue\n",
    "\n",
    "            scheme_AAXA = are_lists_equal(list_indices, [[0,1,3], [2]])\n",
    "            if scheme_AAXA:\n",
    "                rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"AAXA\", lines[line_index:line_index+4])\n",
    "                continue\n",
    "\n",
    "            continue\n",
    "        case 3:\n",
    "            #can be XAXA, AXXA\n",
    "            scheme_XAXA = are_lists_equal(list_indices, [[0],[1,3],[2]])\n",
    "            if scheme_XAXA:\n",
    "                rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"XAXA\", lines[line_index:line_index+4])\n",
    "                continue\n",
    "            \n",
    "            scheme_AXXA = are_lists_equal(list_indices, [[0,3],[1], [2]])\n",
    "            if scheme_AXXA:\n",
    "                rhyme_schemes = add_to_rhyme_schemes(rhyme_schemes, \"AXXA\", lines[line_index:line_index+4])\n",
    "                continue\n",
    "            continue\n",
    "        case 4:\n",
    "            continue # no rhyme scheme found\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
